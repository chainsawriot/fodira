% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/selenium.R
\name{scrape}
\alias{scrape}
\title{Scrape urls and put it in the output directory}
\usage{
scrape(
  urls,
  selen = NULL,
  output_dir = Sys.getenv("ARTICLE_DIR"),
  sleep = 1,
  write = TRUE,
  verbose = FALSE,
  close_selen = FALSE,
  headless = TRUE,
  push = FALSE,
  db = "main",
  collection = "articles",
  prefix = "html",
  delete = TRUE
)
}
\arguments{
\item{urls}{a vector or URLs}

\item{selen}{an instance of Selenium from \code{\link[=gen_selen]{gen_selen()}}. If it is NULL, a new instance is generated and close automatically, i.e. \code{close_selen} is TRUE}

\item{output_dir}{a directory to hold HTML files}

\item{sleep}{sleep time between each collection}

\item{write}{whether to really write the HTML file}

\item{verbose}{whether to display debug information}

\item{close_selen}{whether to close the Selenium instance, to TRUE if \code{selen} is null}

\item{headless}{whether to generate a headless instance, if \code{selen} is null}

\item{push}{whether to update the url and push the html file to the DB}

\item{db}{MongoDB db}

\item{collection}{MongoDB collection}

\item{prefix}{MongoDB GridFS prefix}

\item{delete}{whether to delete the HTML files afterwards.}
}
\value{
a dataframe with urls and filenames; if \code{write} is TRUE, HTML files are written to \code{output_dir}. All failed urls will be skipped.
}
\description{
Scrape urls and put it in the output directory
}
